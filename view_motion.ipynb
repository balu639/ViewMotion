{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b510215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72de6dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/balarusum/Desktop/Bio metrics', '/Users/balarusum/opt/anaconda3/lib/python39.zip', '/Users/balarusum/opt/anaconda3/lib/python3.9', '/Users/balarusum/opt/anaconda3/lib/python3.9/lib-dynload', '', '/Users/balarusum/opt/anaconda3/lib/python3.9/site-packages', '/Users/balarusum/opt/anaconda3/lib/python3.9/site-packages/aeosa']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d204d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/balarusum/Library/Python/3.9/lib/python/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebbb9381",
   "metadata": {
    "id": "ebbb9381"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65dd10c9",
   "metadata": {
    "id": "65dd10c9"
   },
   "outputs": [],
   "source": [
    "# Load Mediapipe solutions\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_face_detection = mp.solutions.face_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29db87be",
   "metadata": {
    "id": "29db87be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Mediapipe solutions\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26e662a3",
   "metadata": {
    "id": "26e662a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@3.255] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/videoio/src/cap_gstreamer.cpp (2386) handleMessage OpenCV | GStreamer warning: your GStreamer installation is missing a required plugin\n",
      "[ WARN:0@3.255] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/videoio/src/cap_gstreamer.cpp (2402) handleMessage OpenCV | GStreamer warning: Embedded video playback halted; module uridecodebin0 reported: Your GStreamer installation is missing a plug-in.\n",
      "[ WARN:0@3.255] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/videoio/src/cap_gstreamer.cpp (1356) open OpenCV | GStreamer warning: unable to start pipeline\n",
      "[ WARN:0@3.255] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture('Video.mp4')\n",
    "# Get the video height and width\n",
    "h = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "w = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7da84",
   "metadata": {
    "id": "f3e7da84"
   },
   "outputs": [],
   "source": [
    "SHRUG_THRESHOLD = 0.6\n",
    "# Loop over the frames in the video\n",
    "while True:\n",
    "    # Read the next frame\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB format\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with Mediapipe solutions\n",
    "    results_hands = hands.process(frame)\n",
    "    results_pose = pose.process(frame)\n",
    "    results_face_detection = face_detection.process(frame)\n",
    "\n",
    "    # Draw bounding boxes on hands\n",
    "    if results_hands.multi_hand_landmarks:\n",
    "        for hand_landmarks in results_hands.multi_hand_landmarks:\n",
    "            x_min, y_min, x_max, y_max = w, h, 0, 0\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                x, y = int(landmark.x * w), int(landmark.y * h)\n",
    "                if x < x_min:\n",
    "                    x_min = x\n",
    "                if y < y_min:\n",
    "                    y_min = y\n",
    "                if x > x_max:\n",
    "                    x_max = x\n",
    "                if y > y_max:\n",
    "                    y_max = y\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
    "\n",
    "    # Draw bounding boxes on faces\n",
    "    if results_face_detection.detections:\n",
    "        for detection in results_face_detection.detections:\n",
    "            x_min, y_min, x_max, y_max = w, h, 0, 0\n",
    "            bbox = detection.location_data.relative_bounding_box\n",
    "            x_min = int(bbox.xmin * w)\n",
    "            y_min = int(bbox.ymin * h)\n",
    "            x_max = int((bbox.xmin + bbox.width) * w)\n",
    "            y_max = int((bbox.ymin + bbox.height) * h)\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 0, 255), 2)\n",
    "     # Draw straight lines on shoulders\n",
    "    if results_pose.pose_landmarks:\n",
    "        left_shoulder_x = int(results_pose.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w)\n",
    "        left_shoulder_y = int(results_pose.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h)\n",
    "        right_shoulder_x = int(results_pose.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w)\n",
    "        right_shoulder_y = int(results_pose.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h)\n",
    "        #cv2.line(frame, (0, left_shoulder_y), (left_shoulder_x - 10, left_shoulder_y), (0, 255, 0), 2)\n",
    "        #cv2.line(frame, (right_shoulder_x + 10, right_shoulder_y), (w, right_shoulder_y), (0, 255, 0), 2)\n",
    "        \n",
    "        # Calculate the distance between the shoulders\n",
    "        shoulder_distance = right_shoulder_x - left_shoulder_x\n",
    "        \n",
    "        # Calculate the midpoint between the left and right shoulders\n",
    "        midpoint_x = (left_shoulder_x + right_shoulder_x) // 2\n",
    "        midpoint_y = (left_shoulder_y + right_shoulder_y) // 2\n",
    "        \n",
    "        \n",
    "\n",
    "        line_y = int(midpoint_y + 0.2 * shoulder_distance)\n",
    "        cv2.line(frame, (left_shoulder_x, line_y), (right_shoulder_x, line_y), (0, 255, 0), 2)\n",
    "\n",
    "        \n",
    "        # Check for shrug\n",
    "        if left_shoulder_y < h * SHRUG_THRESHOLD and right_shoulder_y < h * SHRUG_THRESHOLD:\n",
    "            cv2.putText(frame, \"Shrug detected\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    # Exit if the user presses 'q'\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "video.release()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e21f1",
   "metadata": {
    "id": "6c2e21f1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
